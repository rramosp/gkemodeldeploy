apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: llm-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    name: llm-deployment
    kind: Deployment
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Pods
    pods:
      metric:
        #name: prometheus.googleapis.com|tgi_queue_size|gauge
        name: prometheus.googleapis.com|vllm:num_requests_waiting|gauge
      target:
        type: AverageValue
        averageValue: "5" # Target average queue size
